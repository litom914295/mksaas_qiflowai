{
  "decision": "revise",
  "doc_scope": "PRD+TECH+TASK+UI",
  "scorecard": [
    {"dimension": "value", "score": 4, "evidence": "PRD v5.0 清晰定义了 ICP 和商业模式，MKSaaS 的集成为快速实现 SaaS 核心功能提供了保障。"},
    {"dimension": "fengshui_correctness", "score": 3, "evidence": "TECH v5.0 提到了八字双库融合、玄空飞星引擎，但算法准确性的量化验证标准缺失。"},
    {"dimension": "rag_quality", "score": 2, "evidence": "PRD 和 TECH 文档提及 RAG，但未定义任何端到端验收标准，如准确率、召回率、幻觉率。这是 AI 产品的核心风险。"},
    {"dimension": "multi_tenant_billing", "score": 5, "evidence": "完全复用 MKSaaS 的 Stripe + Credits 体系，方案成熟可靠。"},
    {"dimension": "compliance_safety", "score": 4, "evidence": "继承 MKSaaS 的安全机制，覆盖了 GDPR/CCPA，但需关注命理内容的文化合规性。"},
    {"dimension": "perf_cost", "score": 3, "evidence": "PRD 设定了性能指标，TECH 提出了缓存策略，但 AI API 成本控制依赖于简单的模型路由，缺乏更精细的成本监控和预警机制。"},
    {"dimension": "i18n", "score": 4, "evidence": "基于 next-intl，方案清晰，但 TASK PLAN 中只安排了翻译任务，未涉及多语言环境下的 UI/UX 适配测试。"},
    {"dimension": "evaluation_plan", "score": 1, "evidence": "这是最大的短板。TASK PLAN 中完全没有评测数据集构建、AI 效果回归测试、标注流程等相关任务，无法保证模型迭代后的质量。"},
    {"dimension": "ux", "score": 4, "evidence": "UI_DESIGN_v5.0 非常详尽，融合了东方美学与现代科技，但对置信度和证据的呈现方式不够具体。"},
    {"dimension": "growth_ops", "score": 3, "evidence": "PRD 定义了转化漏斗，但 TASK PLAN 中增长相关任务较笼统，缺乏具体的 A/B 测试和数据驱动的优化排期。"}
  ],
  "issues": [
    {
      "id": "EVAL-001",
      "title": "缺乏系统化的评测体系与回归测试框架",
      "severity": "blocker",
      "cross_doc": true,
      "evidence": "TASK_PLAN_v5.0.md 中只字未提评测数据集的构建、管理和应用。TECH_GUIDE_v5.0.md 虽有测试章节，但仅限于单元/集成/E2E，完全忽略了对 RAG 和 AI 生成内容质量的持续评估。",
      "suggestion": "必须在 TASK_PLAN 中增加一个独立的阶段（或在每个阶段并行）用于'评测体系建设'，包括：1. 定义评测维度（准确性、相关性、无害性）；2. 建立黄金测试集（Golden Set）；3. 开发自动化评测脚本；4. 建立人工标注流程和平台。",
      "owner": "qa",
      "eta_days": 14
    },
    {
      "id": "RAG-001",
      "title": "RAG 端到端验收标准缺失",
      "severity": "high",
      "cross_doc": true,
      "evidence": "PRD_v5.0.md 和 TECH_GUIDE_v5.0.md 均未定义 RAG 系统的验收门槛。例如，在 Top-K 检索中，知识源的召回率应达到多少？最终答案的幻觉率应低于多少？",
      "suggestion": "在 PRD v5.0 中新增'AI质量验收标准'章节，明确定义 RAG 端到端评测指标，例如：Faithfulness > 95%, Answer Relevancy > 90% on Golden Set。",
      "owner": "product",
      "eta_days": 3
    },
    {
      "id": "UI-001",
      "title": "UI 对证据与置信度的呈现方式不够具体",
      "severity": "medium",
      "cross_doc": false,
      "evidence": "UI_DESIGN_v5.0.md 提到了罗盘的'ConfidenceIndicator'和 AI 回复的'SourceCards'，但未说明置信度高低如何通过视觉（如颜色、大小）区分，也未定义'SourceCards'应展示哪些具体信息（如原文片段、来源文档、可信度评分）。",
      "suggestion": "在 UI_DESIGN_v5.0.md 中为'ConfidenceIndicator'和'SourceCards'增加具体设计规范。例如：置信度 >0.9 显示绿色，0.7-0.9 显示黄色，<0.7 显示红色；SourceCard 需包含可点击展开的原文引用和来源链接。",
      "owner": "frontend",
      "eta_days": 2
    },
    {
      "id": "TECH-002",
      "title": "算法与传感器关键阈值未定义为可测试指标",
      "severity": "low",
      "cross_doc": false,
      "evidence": "TECH_GUIDE_v5.0.md 的 API 定义了'confidence'字段，但未说明此分数的计算逻辑以及可接受的阈值。例如，当罗盘置信度低于多少时，应触发 UI 上的校准引导？",
      "suggestion": "在 TECH_GUIDE_v5.0.md 的'测试策略'部分，补充对'confidence'等核心算法输出值的测试用例，明确不同阈值下的预期系统行为。",
      "owner": "backend",
      "eta_days": 1
    }
  ],
  "quick_wins": [
    "立即在 TASK_PLAN 中为算法工程师分配一个'黄金测试集（v1）原型设计'的任务，要求产出一份包含至少 50 个典型案例的 Q&A 数据集。"
  ],
  "open_questions": [
    "命理和风水分析内容在不同文化区域（尤其是西方市场）的合规性风险评估是否已完成？",
    "AI Orchestrator 的多模型路由策略是否考虑了地区访问性和合规性（例如，在某些地区优先使用非 OpenAI 模型）？"
  ],
  "prd_patch": "### PRD_v5.0.md 补丁\n```markdown\n--- a/docs/PRD_v5.0.md\n+++ b/docs/PRD_v5.0.md\n@@ -520,6 +520,19 @@\n \n ---\r\n \n+## 9.5 AI质量与RAG验收标准\n+\n+### 9.5.1 RAG 端到端验收标准\n+- **Faithfulness (忠实度)**: > 95%。AI生成答案中，有来源支撑的比例。\n+- **Answer Relevancy (相关性)**: > 90%。答案与用户问题的相关程度。\n+- **Context Precision (上下文准确率)**: > 95%。检索到的上下文与问题相关的比例。\n+- **Hallucination Rate (幻觉率)**: < 2%。在标准测试集上，生成完全错误信息的比率。\n+\n+### 9.5.2 传感器置信度标准\n+- **罗盘置信度**: UI呈现必须与后端置信度评分挂钩，分为高(>0.9)、中(0.7-0.9)、低(<0.7)三档，并有明确的视觉区分。\n+\n ## 9. 开发计划\n \n ### Phase 1: 基础架构 (Week 1-2)\n```",
  "tech_patch": "### TECH_GUIDE_v5.0.md 补丁\n```markdown\n--- a/docs/TECH_GUIDE_v5.0.md\n+++ b/docs/TECH_GUIDE_v5.0.md\n@@ -642,6 +642,12 @@\n - Bazi：边界（闰月/时辰边界/真太阳时）；双库不一致时的融合结果\r\n - XuanKong：兼向、元运切换；飞星路径校验\r\n - AI：多模型 fallback；超时/重试；引用完整性\r\n - 支付：订阅生命周期、Webhook 重放、积分扣费幂等\n+\n+### 20.4 算法与传感器阈值测试\n+- **罗盘置信度测试**: 模拟不同的传感器噪声输入，验证 `compassConfidence` 输出值。当 `compassConfidence` < 0.7 时，必须触发前端的“重新校准”提示。\n+- **八字融合置信度测试**: 构造已知存在差异的双库输入，验证 `bazi.meta.confidence` < 1.0，并检查数据库中是否正确记录。\n \r\n ---\\n \n ## 21. 与 PRD v5.0 的对齐关系\n```",
  "task_patch": "### TASK_PLAN_v5.0.md 补丁\n```markdown\n--- a/docs/TASK_PLAN_v5.0.md\n+++ b/docs/TASK_PLAN_v5.0.md\n@@ -138,6 +138,20 @@\n \n **验收标准**: Lighthouse评分>90，无严重Bug\r\n \n+---\r\n+\n+## 第五阶段 B：评测体系建设 (Sprint 6并行, 2周)\n+\n+### 5.3 评测数据集建设\n+- [ ] (算法工程师) 设计并产出八字/风水黄金测试集v1 (至少50例)\n+- [ ] (产品经理) 审核并确认黄金测试集v1的准确性\n+- [ ] (全栈开发) 搭建测试集管理后台，支持增删改查\n+\n+### 5.4 自动化评测框架\n+- [ ] (全栈开发) 开发针对黄金测试集的自动化回归测试脚本\n+- [ ] (全栈开发) 集成RAGAS等框架，实现对Faithfulness、Relevancy的量化评估\n+- [ ] (全- [ ] (全栈开发) 将自动化评测任务加入CI/CD流程\n+\n **验收标准**: CI/CD中包含可自动运行的AI质量回归测试，并生成评测报告。\n+\n ---\"
}
